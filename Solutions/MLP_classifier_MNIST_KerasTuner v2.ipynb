{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**MLP classifier trained on the MNIST dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image classification using the MNIST dataset\n",
    "We will train and evaluate an MLP on the MNIST dataset. It consists of 70.000 grayscale images of 28x28 pixels each, and there are 10 classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common imports\n",
    "import sys\n",
    "import os\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Ignore useless warnings (see SciPy issue #5998)\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "(X_train_full, y_train_full), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the size and dimension of the dataset.\n",
    "X_train_full.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Each pixel intensity is represented as a byte (0 to 255).\n",
    "X_train_full.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the full training set into a validation set and a (smaller) training set.\n",
    "X_valid, X_train = X_train_full[:5000], X_train_full[5000:]\n",
    "y_valid, y_train = y_train_full[:5000], y_train_full[5000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning with KerasTuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install KerasTuner if you are using Google Colab (if you are running on your own computer\n",
    "# it may also be necessary to install KerasTuner once from the command prompt).\n",
    "if \"google.colab\" in sys.modules:\n",
    "    %pip install -q -U keras_tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function that builds, compiles and returns a Keras model.\n",
    "# Note that the function takes a HyperParameters object (hp) as a parameter, which it can\n",
    "# use to define hyperparameters along with their range of possible values.\n",
    "import keras_tuner as kt\n",
    "\n",
    "def build_model(hp):\n",
    "    n_hidden = hp.Int(\"n_hidden\", min_value=2, max_value=12)\n",
    "    n_neurons = hp.Int(\"n_neurons\", min_value=150, max_value=300)\n",
    "\n",
    "    # Momentum optimization\n",
    "    optimizer = tf.keras.optimizers.SGD(momentum=0.9)\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "\n",
    "    # Rescaling layer (divides each pixel by 255):\n",
    "    model.add(keras.layers.Rescaling(1./255))\n",
    "\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    for _ in range(n_hidden):\n",
    "        model.add(tf.keras.layers.Dense(n_neurons, activation=\"relu\"))\n",
    "        \n",
    "    # Dropout    \n",
    "    model.add(keras.layers.Dropout(rate=0.2))\n",
    "    \n",
    "    model.add(tf.keras.layers.Dense(10, activation=\"softmax\"))\n",
    "    \n",
    "    model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=optimizer,\n",
    "                  metrics=[\"accuracy\"])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 50 Complete [00h 00m 49s]\n",
      "val_accuracy: 0.9846000075340271\n",
      "\n",
      "Best val_accuracy So Far: 0.9868000149726868\n",
      "Total elapsed time: 00h 34m 30s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Use KerasTuner RandomSearch to tune hyperparameters\n",
    "random_search_tuner = kt.RandomSearch(\n",
    "    build_model, objective=\"val_accuracy\", max_trials=100, overwrite=True,\n",
    "    directory=\"my_mnist\", project_name=\"my_rnd_search\", seed=42)\n",
    "\n",
    "# Early stopping\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True)\n",
    "\n",
    "# Learning rate scheduling\n",
    "lr_scheduler = keras.callbacks.ReduceLROnPlateau(factor=0.5, patience=3)\n",
    "\n",
    "# The parameters that you can pass to the search() method are similar to the\n",
    "# parameters that you can pass to the fit() method of a Keras model.\n",
    "# Here I have doubled the batch size compared to the default value to speed up\n",
    "# training, and I use callbacks.\n",
    "random_search_tuner.search(X_train, y_train, epochs=80, batch_size=64, \n",
    "                           callbacks=[lr_scheduler, early_stopping_cb],\n",
    "                           validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial summary\n",
      "Hyperparameters:\n",
      "n_hidden: 7\n",
      "n_neurons: 234\n",
      "Score: 0.9868000149726868\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the best model:\n",
    "best_trial = random_search_tuner.oracle.get_best_trials(num_trials=1)[0]\n",
    "best_trial.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9868000149726868"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the best model's accuracy measured on the validation set:\n",
    "best_trial.metrics.get_last_value(\"val_accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 0s 827us/step - loss: 0.1207 - accuracy: 0.9841\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's accuracy on the test set:\n",
    "best_model = random_search_tuner.get_best_models(num_models=1)[0]\n",
    "test_loss, test_accuracy = best_model.evaluate(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "nav_menu": {
   "height": "264px",
   "width": "369px"
  },
  "toc": {
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 6,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
